{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision as tv\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, cosine_distances\n",
    "\n",
    "from model_phrase_mlm import TextEncoder, ImageEncoder\n",
    "from transformers import BertConfig\n",
    "\n",
    "from misc.config import Config\n",
    "cfg  = Config()\n",
    "cfg.GPU_ID = 2\n",
    "\n",
    "torch.cuda.set_device(cfg.GPU_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DIM = 2048\n",
    "\n",
    "train_transform = tv.transforms.Compose([\n",
    "    tv.transforms.RandomRotation(15), # rotation will cost 0.1s for each 10 images\n",
    "    tv.transforms.RandomCrop(MAX_DIM, pad_if_needed=True), # 0.6s for each 10 images\n",
    "    tv.transforms.ColorJitter(brightness=[0.5, 1.8] # colorjitter will cost 0.32s for each 10 images\n",
    "                              , contrast=[0.5, 1.8]\n",
    "                              , saturation=[0.5, 1.8]),\n",
    "    tv.transforms.ToTensor(), \n",
    "    tv.transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "val_transform = tv.transforms.Compose([\n",
    "    tv.transforms.CenterCrop(MAX_DIM),\n",
    "    tv.transforms.ToTensor(),  \n",
    "    tv.transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "class MimicDataset(Dataset):\n",
    "    def __init__(self, root, dataset, max_length, transform=val_transform, mode='test'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.root = root #save dir\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "#         vocab='allenai/scibert_scivocab_uncased'\n",
    "#         self.tokenizer = BertTokenizer.from_pretrained(vocab, do_lower=True)\n",
    "\n",
    "        self.datadict = dataset['data_dict'] # uid: {text:text, filenames:[filename]}\n",
    "        if self.mode == 'train':\n",
    "            self.keys = dataset['data_split']['train_uids'] # uid list\n",
    "        elif self.mode == 'val':\n",
    "            self.keys = dataset['data_split']['val_uids'] # uid list\n",
    "        elif self.mode == 'test':\n",
    "            self.keys = dataset['data_split']['test_uids'] # uid list\n",
    "        \n",
    "        self.idx2word = dataset['idx2word']\n",
    "        self.idx2word[8410] = '[MASK]'\n",
    "        self.word2ids = dataset['word2idx']\n",
    "        self.word2ids['[MASK]'] = 8410\n",
    "        self.__sep_id__ = dataset['word2idx']['[SEP]']\n",
    "        self.vocab_size = len(dataset['word2idx'])\n",
    "        self.max_length = max_length + 1\n",
    "        \n",
    "#         self.err_log = os.path.join(log_dir, 'err.log') # create error log\n",
    "#         if not os.path.exists(self.err_log):\n",
    "#             with open(self.err_log, 'w') as f:\n",
    "#                 f.write('Epoch 0:\\n\\n')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        uid = self.keys[idx]\n",
    "        \n",
    "        image_id = np.random.choice(self.datadict[uid]['filenames'])# get one file name randomly\n",
    "        image_path = os.path.join(self.root, image_id.replace('dcm','jpg')) #original used 'jpg', try 'png'\n",
    "\n",
    "        try:\n",
    "            with Image.open(image_path) as img: \n",
    "                if self.transform:\n",
    "                    image = self.transform(img)\n",
    "\n",
    "        except Exception as ex:\n",
    "#             with open(self.err_log, 'a+') as f:\n",
    "#                 f.write('%s\\nERR_IMG %s\\n' % (ex, image_path))\n",
    "            print(ex)\n",
    "            print(image_path)\n",
    "            return None ## return None, collate_fn will ignore this broken sample\n",
    "        \n",
    "        max_len_array = np.zeros(self.max_length, dtype='int')\n",
    "        cap_mask = np.zeros(self.max_length, dtype='int')\n",
    "        caption = np.array(self.datadict[uid]['token_ids'])\n",
    "        if len(caption)<=self.max_length:\n",
    "            cap_mask[:len(caption)] = 1\n",
    "            max_len_array[:len(caption)] = caption\n",
    "        else:\n",
    "            cap_mask[:] = 1\n",
    "            max_len_array = caption[:self.max_length]\n",
    "            max_len_array[-1] = self.__sep_id__\n",
    "        caption = max_len_array\n",
    "        cap_mask = cap_mask.astype(bool)\n",
    "        cap_lens = cap_mask.sum(-1)\n",
    "        return image, caption, cap_mask, uid, cap_lens\n",
    "    \n",
    "def build_dataset(mode='test', cfg=None, out_dir=None):\n",
    "    data_dir = cfg.dataset_root\n",
    "    img_dir = os.path.join(data_dir, 'physionet.org/files/', 'mimic-cxr-jpg/2.0.0/')\n",
    "    with open(os.path.join(data_dir,'lm_reports/mimic_dataset_mit_normalized.pkl'),'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    if mode == 'train':\n",
    "        data = MimicDataset(img_dir, dataset, \n",
    "                               max_length=cfg.max_length, mode=mode, \n",
    "                               transform=train_transform)\n",
    "        return data\n",
    "\n",
    "    elif mode == 'val':\n",
    "        data = MimicDataset(img_dir, dataset, \n",
    "                               max_length=cfg.max_length, mode=mode, \n",
    "                               transform=val_transform)\n",
    "        return data\n",
    "    \n",
    "    elif mode == 'test':\n",
    "        data = MimicDataset(img_dir, dataset, \n",
    "                               max_length=cfg.max_length, mode=mode, \n",
    "                               transform=val_transform)\n",
    "        return data\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(f\"{mode} not supported\")\n",
    "        \n",
    "## collate_fn for handling None type item due to image corruption ##\n",
    "## This will return batch size - broken image number ##\n",
    "def collate_fn_ignore_none(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    return torch.utils.data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set 3000 is loaded.\n",
      "Vocab size is 8411.\n"
     ]
    }
   ],
   "source": [
    "test_set = build_dataset('test', cfg)\n",
    "print('Testing set %d is loaded.' % len(test_set))\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                test_set, batch_size=50, \n",
    "                collate_fn=collate_fn_ignore_none, drop_last=False,\n",
    "                shuffle=False, num_workers=2, pin_memory=False)\n",
    "print('Vocab size is %d.' % test_set.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load image encoder checkpoint from: /media/My1TBSSD1/IPMI2021/output/MIMIC_phrase_ft_2021_03_02_02_25_32/Model/image_encoder29.pth\n",
      "Load text encoder checkpoint from: /media/My1TBSSD1/IPMI2021/output/MIMIC_phrase_ft_2021_03_02_02_25_32/Model/text_encoder29.pth\n"
     ]
    }
   ],
   "source": [
    "bert_config = BertConfig(vocab_size=test_loader.dataset.vocab_size, hidden_size=512, num_hidden_layers=3,\n",
    "                    num_attention_heads=8, intermediate_size=2048, hidden_act='gelu',\n",
    "                    hidden_dropout_prob=cfg.hidden_dropout_prob, attention_probs_dropout_prob=cfg.attention_probs_dropout_prob,\n",
    "                    max_position_embeddings=512, layer_norm_eps=1e-12,\n",
    "                    initializer_range=0.02, type_vocab_size=2, pad_token_id=0)\n",
    "\n",
    "##### change the checkpoint path here #####\n",
    "cfg.text_encoder_path = '/media/My1TBSSD1/IPMI2021/output/MIMIC_phrase_ft_2021_03_02_02_25_32/Model/text_encoder29.pth'\n",
    "# ################### encoders ################################# #      \n",
    "image_encoder = ImageEncoder(output_channels=cfg.hidden_dim)\n",
    "text_encoder = TextEncoder(bert_config=bert_config, output_channels=cfg.hidden_dim)\n",
    "\n",
    "if cfg.CUDA:\n",
    "    text_encoder = text_encoder.cuda()\n",
    "    image_encoder = image_encoder.cuda()\n",
    "    \n",
    "if cfg.text_encoder_path != '':\n",
    "    img_encoder_path = cfg.text_encoder_path.replace('text_encoder', 'image_encoder')\n",
    "    print('Load image encoder checkpoint from:', img_encoder_path)\n",
    "    state_dict = torch.load(img_encoder_path, map_location='cpu')\n",
    "    image_encoder.load_state_dict(state_dict['model'])\n",
    "\n",
    "    text_encoder_path = cfg.text_encoder_path\n",
    "    print('Load text encoder checkpoint from:', text_encoder_path)\n",
    "    state_dict = torch.load(text_encoder_path, map_location='cpu')\n",
    "    text_encoder.load_state_dict(state_dict['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def testing(cnn_model, trx_model, dataloader):\n",
    "    cnn_model.eval()\n",
    "    trx_model.eval()\n",
    "    #####################################\n",
    "    v_feat = []\n",
    "    t_feat = []\n",
    "    uids = []\n",
    "    val_data_iter = iter(dataloader)\n",
    "    \n",
    "    for step in tqdm(range(len(val_data_iter))):\n",
    "        real_imgs, captions, masks, class_ids, cap_lens = val_data_iter.next()\n",
    "        if cfg.CUDA:\n",
    "            real_imgs, captions, masks, cap_lens = real_imgs.cuda(), captions.cuda(), masks.cuda(), cap_lens.cuda()\n",
    "        v_r, v_g, _, _, _, _ = cnn_model(real_imgs)\n",
    "        t_w, t_b, t_t, t_g = trx_model(captions, masks)\n",
    "        v_feat.append(v_g.detach().cpu().numpy())\n",
    "        t_feat.append(t_g.detach().cpu().numpy())\n",
    "        uids += class_ids.tolist()\n",
    "        \n",
    "    v_feat = np.concatenate(v_feat, axis=0)\n",
    "    t_feat = np.concatenate(t_feat, axis=0)\n",
    "    \n",
    "    return v_feat, t_feat, uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:20<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 512) (3000, 512) 3000\n"
     ]
    }
   ],
   "source": [
    "v_feat, t_feat, uids = testing(image_encoder, text_encoder, test_loader)\n",
    "print(v_feat.shape, t_feat.shape, len(uids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1853\t0.4567\t0.5843\n"
     ]
    }
   ],
   "source": [
    "## I2T R - 1k here ##\n",
    "ks = 1000\n",
    "coss = []\n",
    "tp1s = []\n",
    "tp5s = []\n",
    "tp10s = []\n",
    "for i in range(3):\n",
    "    cos = cosine_similarity(v_feat[i*ks:(i+1)*ks], t_feat[i*ks:(i+1)*ks])\n",
    "    cos = np.array(cos)\n",
    "    coss.append(cos)\n",
    "#     print(cos.shape)\n",
    "    tp = cos.argsort()[:,-10:][:,::-1] # top10\n",
    "    sn = tp.shape[0]\n",
    "    gt = np.repeat(np.arange(sn).reshape(sn,1), 10, axis=1)\n",
    "    hits = np.equal(tp,gt)\n",
    "    top1 = hits[:,:1].any(axis=1).sum() / hits.shape[0]\n",
    "    top5 = hits[:,:5].any(axis=1).sum() / hits.shape[0]\n",
    "    top10 = hits[:,:10].any(axis=1).sum() / hits.shape[0]\n",
    "    tp1s.append(top1)\n",
    "    tp5s.append(top5)\n",
    "    tp10s.append(top10)\n",
    "    \n",
    "print('%.4f\\t%.4f\\t%.4f' % (np.mean(tp1s), np.mean(tp5s), np.mean(tp10s)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1883\t0.4513\t0.5800\n"
     ]
    }
   ],
   "source": [
    "## T2I R - 1k here ##\n",
    "ks = 1000\n",
    "coss = []\n",
    "tp1s = []\n",
    "tp5s = []\n",
    "tp10s = []\n",
    "for i in range(3):\n",
    "    cos = cosine_similarity(t_feat[i*ks:(i+1)*ks], v_feat[i*ks:(i+1)*ks])\n",
    "    cos = np.array(cos)\n",
    "    coss.append(cos)\n",
    "#     print(cos.shape)\n",
    "    tp = cos.argsort()[:,-10:][:,::-1] # top10\n",
    "    sn = tp.shape[0]\n",
    "    gt = np.repeat(np.arange(sn).reshape(sn,1), 10, axis=1)\n",
    "    hits = np.equal(tp,gt)\n",
    "    top1 = hits[:,:1].any(axis=1).sum() / hits.shape[0]\n",
    "    top5 = hits[:,:5].any(axis=1).sum() / hits.shape[0]\n",
    "    top10 = hits[:,:10].any(axis=1).sum() / hits.shape[0]\n",
    "    tp1s.append(top1)\n",
    "    tp5s.append(top5)\n",
    "    tp10s.append(top10)\n",
    "    \n",
    "print('%.4f\\t%.4f\\t%.4f' % (np.mean(tp1s), np.mean(tp5s), np.mean(tp10s)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 3000)\n",
      "0.1140\t0.3297\t0.4357\n"
     ]
    }
   ],
   "source": [
    "## I2T R - 3k here ##\n",
    "ks = 3000\n",
    "cos = cosine_similarity(v_feat, t_feat)\n",
    "cos = np.array(cos)\n",
    "print(cos.shape)\n",
    "tp = cos.argsort()[:,-10:][:,::-1] # top10\n",
    "sn = tp.shape[0]\n",
    "gt = np.repeat(np.arange(sn).reshape(sn,1), 10, axis=1)\n",
    "hits = np.equal(tp,gt)\n",
    "top1 = hits[:,:1].any(axis=1).sum() / hits.shape[0]\n",
    "top5 = hits[:,:5].any(axis=1).sum() / hits.shape[0]\n",
    "top10 = hits[:,:10].any(axis=1).sum() / hits.shape[0]\n",
    "\n",
    "print('%.4f\\t%.4f\\t%.4f' % (np.mean(top1), np.mean(top5), np.mean(top10)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 3000)\n",
      "0.1237\t0.3187\t0.4327\n"
     ]
    }
   ],
   "source": [
    "## T2I R - 3k here ##\n",
    "ks = 3000\n",
    "cos = cosine_similarity(t_feat, v_feat)\n",
    "cos = np.array(cos)\n",
    "print(cos.shape)\n",
    "tp = cos.argsort()[:,-10:][:,::-1] # top10\n",
    "sn = tp.shape[0]\n",
    "gt = np.repeat(np.arange(sn).reshape(sn,1), 10, axis=1)\n",
    "hits = np.equal(tp,gt)\n",
    "top1 = hits[:,:1].any(axis=1).sum() / hits.shape[0]\n",
    "top5 = hits[:,:5].any(axis=1).sum() / hits.shape[0]\n",
    "top10 = hits[:,:10].any(axis=1).sum() / hits.shape[0]\n",
    "\n",
    "print('%.4f\\t%.4f\\t%.4f' % (np.mean(top1), np.mean(top5), np.mean(top10)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
