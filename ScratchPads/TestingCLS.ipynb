{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision as tv\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, cosine_distances\n",
    "\n",
    "from model_old import ImageEncoder_Classification\n",
    "# from transformers import BertConfig\n",
    "\n",
    "from misc.config import Config\n",
    "cfg  = Config()\n",
    "cfg.GPU_ID = 2\n",
    "\n",
    "torch.cuda.set_device(cfg.GPU_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DIM = 2048\n",
    "\n",
    "train_transform = tv.transforms.Compose([\n",
    "    tv.transforms.RandomRotation(15), # rotation will cost 0.1s for each 10 images\n",
    "    tv.transforms.RandomCrop(MAX_DIM, pad_if_needed=True), # 0.6s for each 10 images\n",
    "    tv.transforms.ColorJitter(brightness=[0.5, 1.8] # colorjitter will cost 0.32s for each 10 images\n",
    "                              , contrast=[0.5, 1.8]\n",
    "                              , saturation=[0.5, 1.8]),\n",
    "    tv.transforms.ToTensor(), \n",
    "    tv.transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "val_transform = tv.transforms.Compose([\n",
    "    tv.transforms.CenterCrop(MAX_DIM),\n",
    "    tv.transforms.ToTensor(),  \n",
    "    tv.transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "class MimicDataset(Dataset):\n",
    "    def __init__(self, root, dataset, max_length, transform=train_transform, mode='train'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.root = root #save dir\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "        self.classes = dataset['label'] # multi-label one-hot vector\n",
    "        self.datadict = dataset['image'] # uid: {text:text, filenames:[filename]}\n",
    "        if self.mode == 'train':\n",
    "            self.keys = dataset['split']['train'] # uid list\n",
    "        elif self.mode == 'val':\n",
    "            self.keys = np.concatenate([dataset['split']['val1'], dataset['split']['val2']]) # uid list\n",
    "        elif self.mode == 'val2':\n",
    "            self.keys = dataset['split']['val2'] # uid list\n",
    "        elif self.mode == 'test':\n",
    "            self.keys = dataset['split']['test'] # uid list\n",
    "            \n",
    "        self.class_to_idx = {\n",
    "            'Atelectasis': 0, 'Cardiomegaly': 1, 'Consolidation': 2, 'Edema': 3, 'Enlarged Cardiomediastinum': 4, \n",
    "            'Fracture': 5, 'Lung Lesion': 6, 'Lung Opacity': 7, 'No Finding': 8, 'Pleural Effusion': 9, \n",
    "            'Pleural Other': 10, 'Pneumonia': 11, 'Pneumothorax': 12, 'Support Devices': 13\n",
    "        }\n",
    "        \n",
    "        self.idx_to_class = {\n",
    "            0:'Atelectasis', 1:'Cardiomegaly', 2:'Consolidation', 3:'Edema', 4:'Enlarged Cardiomediastinum', \n",
    "            5:'Fracture', 6:'Lung Lesion', 7:'Lung Opacity', 8:'No Finding', 9:'Pleural Effusion', \n",
    "            10:'Pleural Other', 11:'Pneumonia', 12:'Pneumothorax', 13:'Support Devices'\n",
    "        }\n",
    "        \n",
    "        self.num_classes = 14\n",
    "        \n",
    "#         self.err_log = os.path.join(log_dir, 'err.log') # create error log\n",
    "#         if not os.path.exists(self.err_log):\n",
    "#             with open(self.err_log, 'w') as f:\n",
    "#                 f.write('Epoch 0:\\n\\n')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        uid = self.keys[idx]\n",
    "        \n",
    "        image_id = np.random.choice(self.datadict[uid]['filenames'])# get one file name randomly\n",
    "        image_path = os.path.join(self.root, image_id.replace('dcm','jpg')) #original used 'jpg', try 'png'\n",
    "\n",
    "        try:\n",
    "            with Image.open(image_path) as img: \n",
    "                if self.transform:\n",
    "                    image = self.transform(img)\n",
    "\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "#             with open(self.err_log, 'a+') as f:\n",
    "#                 f.write('%s\\nERR_IMG %s\\n' % (ex, image_path))\n",
    "            return None ## return None, collate_fn will ignore this broken sample\n",
    "        \n",
    "        classes = torch.tensor(self.classes[uid]).float()\n",
    "        \n",
    "        return image, classes, uid\n",
    "        \n",
    "\n",
    "def build_dataset(mode='train', cfg=None):\n",
    "    data_dir = cfg.dataset_root\n",
    "    img_dir = os.path.join(data_dir, 'physionet.org/files/', 'mimic-cxr-jpg/2.0.0/')\n",
    "    with open(os.path.join(data_dir, 'lm_reports/class_label_mit.pkl'), 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    if mode == 'train':\n",
    "        data = MimicDataset(img_dir, dataset, \n",
    "                               max_length=cfg.max_length, mode=mode, \n",
    "                               transform=train_transform)\n",
    "        return data\n",
    "\n",
    "    elif mode == 'val':\n",
    "        data = MimicDataset(img_dir, dataset, \n",
    "                               max_length=cfg.max_length, mode=mode, \n",
    "                               transform=val_transform)\n",
    "        return data\n",
    "    \n",
    "    elif mode == 'val2':\n",
    "        data = MimicDataset(img_dir, dataset, \n",
    "                               max_length=cfg.max_length, mode=mode, \n",
    "                               transform=val_transform)\n",
    "        return data\n",
    "    \n",
    "    elif mode == 'test':\n",
    "        data = MimicDataset(img_dir, dataset, \n",
    "                               max_length=cfg.max_length, mode=mode, \n",
    "                               transform=val_transform)\n",
    "        return data\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(f\"{mode} not supported\")\n",
    "        \n",
    "## collate_fn for handling None type item due to image corruption ##\n",
    "## This will return batch size - broken image number ##\n",
    "def collate_fn_ignore_none(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    return torch.utils.data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set 4999 is loaded.\n"
     ]
    }
   ],
   "source": [
    "test_set = build_dataset('val', cfg)\n",
    "# test_set = build_dataset('test', cfg)\n",
    "print('Testing set %d is loaded.' % len(test_set))\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                test_set, batch_size=50, \n",
    "                collate_fn=collate_fn_ignore_none, drop_last=False,\n",
    "                shuffle=False, num_workers=8, pin_memory=False)\n",
    "# print('Vocab size is %d.' % test_set.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load image encoder checkpoint from: /media/My1TBSSD1/IPMI2021/pretrained/image_encoder14.pth\n"
     ]
    }
   ],
   "source": [
    "##### change the checkpoint path here #####\n",
    "# raw checkpoint: '/media/My1TBSSD1/IPMI2021/output/MIMIC_class_raw_2020_12_09_22_17_55/Model/image_encoder25.pth'\n",
    "# fz checkpoint: '/media/My1TBSSD1/IPMI2021/pretrained/image_encoder14.pth'\n",
    "# ft checkpoint: '/media/My1TBSSD1/IPMI2021/output/MIMIC_class_ft_2020_12_11_09_18_56/Model/image_encoder12.pth'\n",
    "cfg.text_encoder_path = '/media/My1TBSSD1/IPMI2021/pretrained/image_encoder14.pth'\n",
    "# ################### encoders ################################# #      \n",
    "image_encoder = ImageEncoder_Classification(num_class=14, encoder_path='', pretrained=False, cfg = cfg)\n",
    "\n",
    "if cfg.CUDA:\n",
    "    image_encoder = image_encoder.cuda()\n",
    "    \n",
    "if cfg.text_encoder_path != '':\n",
    "    img_encoder_path = cfg.text_encoder_path.replace('text_encoder', 'image_encoder')\n",
    "    print('Load image encoder checkpoint from:', img_encoder_path)\n",
    "    state_dict = torch.load(img_encoder_path, map_location='cpu')\n",
    "    image_encoder.load_state_dict(state_dict['model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(cnn_model, dataloader_val):\n",
    "    cnn_model.eval()\n",
    "    val_data_iter = iter(dataloader_val)\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    class_auc = []\n",
    "    #####################################\n",
    "    for step in tqdm(range(len(val_data_iter))):  \n",
    "        real_imgs, classes, uids = val_data_iter.next()\n",
    "        if cfg.CUDA:\n",
    "            real_imgs, classes = real_imgs.cuda(), classes.cuda()\n",
    "\n",
    "        y_pred = cnn_model(real_imgs)\n",
    "        y_pred_sigmoid = torch.sigmoid(y_pred)\n",
    "        y_preds.append(y_pred_sigmoid.detach().cpu().numpy())\n",
    "        y_trues.append(classes.detach().cpu().numpy())\n",
    "\n",
    "    y_preds = np.concatenate(y_preds,axis=0)\n",
    "    y_trues = np.concatenate(y_trues,axis=0)\n",
    "    for i in range(y_preds.shape[-1]):\n",
    "        class_auc.append(roc_auc_score(y_trues[:,i],y_preds[:,i]))\n",
    "\n",
    "    return class_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:06<00:00,  1.51it/s]\n"
     ]
    }
   ],
   "source": [
    "auc = evaluate(image_encoder, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atelectasis: 0.8208\n",
      "Cardiomegaly: 0.8183\n",
      "Consolidation: 0.8074\n",
      "Edema: 0.8895\n",
      "Enlarged Cardiomediastinum: 0.7566\n",
      "Fracture: 0.6757\n",
      "Lung Lesion: 0.7187\n",
      "Lung Opacity: 0.7539\n",
      "No Finding: 0.8733\n",
      "Pleural Effusion: 0.9048\n",
      "Pleural Other: 0.8396\n",
      "Pneumonia: 0.7498\n",
      "Pneumothorax: 0.8527\n",
      "Support Devices: 0.9137\n",
      "Avg: 0.8078\n",
      "wAvg: 0.8397\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(auc)):\n",
    "    print('%s: %.4f' % (test_loader.dataset.idx_to_class[idx], auc[idx]))\n",
    "\n",
    "avg= np.mean(np.array(auc)[[0,1,2,3,4,5,6,7,9,10,11,12,13]])\n",
    "print('Avg: %.4f' % avg)\n",
    "\n",
    "# weight = np.array([679, 808, 191, 659, 132, 78, 108, 974, 539, 990, 52, 309, 94, 1061]) # weight for hold_out_set\n",
    "# weight = np.array([958, 997, 233, 600, 174, 79, 168, 1134, 1636, 1243, 31, 361, 234, 1566]) # weight for val+test set\n",
    "# weight = np.array([566, 575, 131, 354, 110, 33, 105, 650, 1017, 710, 28, 227, 124, 881]) # weight for val2 set\n",
    "weight = np.array([566, 575, 131, 354, 110, 33, 105, 650, 710, 28, 227, 124, 881]) # weight for val2 set\n",
    "\n",
    "weight = weight / weight.sum()\n",
    "wavg = np.array(auc)[[0,1,2,3,4,5,6,7,9,10,11,12,13]] @ weight\n",
    "print('wAvg: %.4f' % wavg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[958, 997, 233, 600, 174, 79, 168, 1134, 1636, 1243, 31, 361, 234, 1566]\n"
     ]
    }
   ],
   "source": [
    "## statistic for val sets and test sets\n",
    "hold = np.array([679, 808, 191, 659, 132, 78, 108, 974, 539, 990, 52, 309, 94, 1061])\n",
    "val1 = np.array([392, 422, 102, 246, 64, 46, 63, 484, 619, 533, 19, 134, 110, 685])\n",
    "val2 = np.array([566, 575, 131, 354, 110, 33, 105, 650, 1017, 710, 12, 227, 124, 881])\n",
    "print(list((val1+val2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566\n",
      "575\n",
      "131\n",
      "354\n",
      "110\n",
      "33\n",
      "105\n",
      "650\n",
      "1017\n",
      "710\n",
      "12\n",
      "227\n",
      "124\n",
      "881\n"
     ]
    }
   ],
   "source": [
    "for i in val2:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
