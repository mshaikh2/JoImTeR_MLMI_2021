{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision as tv\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, cosine_distances\n",
    "\n",
    "from model_mlm_cls import Text_Classification\n",
    "from transformers import BertConfig\n",
    "\n",
    "from misc.config import Config\n",
    "cfg  = Config()\n",
    "cfg.GPU_ID = 1\n",
    "\n",
    "torch.cuda.set_device(cfg.GPU_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DIM = 2048\n",
    "\n",
    "train_transform = tv.transforms.Compose([\n",
    "    tv.transforms.RandomRotation(15),  # rotation will cost 0.1s for each 10 images\n",
    "    tv.transforms.RandomCrop(MAX_DIM, pad_if_needed=True),  # 0.6s for each 10 images\n",
    "    tv.transforms.ColorJitter(brightness=[0.5, 1.8]  # colorjitter will cost 0.32s for each 10 images\n",
    "                              , contrast=[0.5, 1.8]\n",
    "                              , saturation=[0.5, 1.8]),\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "val_transform = tv.transforms.Compose([\n",
    "    tv.transforms.CenterCrop(MAX_DIM),\n",
    "    tv.transforms.ToTensor(),\n",
    "    tv.transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "\n",
    "class MimicDataset(Dataset):\n",
    "    def __init__(self, root, dataset, max_length, transform=train_transform, mode='train', log_dir='test'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.root = root  #save dir\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "        self.classes = dataset['label']  # multi-label one-hot vector\n",
    "        self.datadict = dataset['image']  # uid: {text:text, filenames:[filename]}\n",
    "        if self.mode == 'train':\n",
    "            self.keys = dataset['split']['train']  # uid list\n",
    "        elif self.mode == 'val':\n",
    "            self.keys = np.concatenate([dataset['split']['val1'], dataset['split']['val2']])  # uid list\n",
    "        elif self.mode == 'val2':\n",
    "            self.keys = dataset['split']['val2']  # uid list\n",
    "        elif self.mode == 'test':\n",
    "            self.keys = dataset['split']['test']  # uid list\n",
    "\n",
    "        self.idx2word = dataset['idx2word']\n",
    "        self.idx2word[8410] = '[MASK]'\n",
    "        self.word2idx = dataset['word2idx']\n",
    "        self.word2idx['[MASK]'] = 8410\n",
    "        self.__sep_id__ = dataset['word2idx']['[SEP]']\n",
    "        self.vocab_size = len(dataset['word2idx'])\n",
    "        self.max_length = max_length + 1\n",
    "        #         self.__mask_id__ = 8410 # [MASK] token id\n",
    "\n",
    "        ## classification params\n",
    "        self.class_to_idx = {\n",
    "            'Atelectasis': 0, 'Cardiomegaly': 1, 'Consolidation': 2, 'Edema': 3, 'Enlarged Cardiomediastinum': 4,\n",
    "            'Fracture': 5, 'Lung Lesion': 6, 'Lung Opacity': 7, 'No Finding': 8, 'Pleural Effusion': 9,\n",
    "            'Pleural Other': 10, 'Pneumonia': 11, 'Pneumothorax': 12, 'Support Devices': 13\n",
    "        }\n",
    "\n",
    "        self.idx_to_class = {\n",
    "            0: 'Atelectasis', 1: 'Cardiomegaly', 2: 'Consolidation', 3: 'Edema', 4: 'Enlarged Cardiomediastinum',\n",
    "            5: 'Fracture', 6: 'Lung Lesion', 7: 'Lung Opacity', 8: 'No Finding', 9: 'Pleural Effusion',\n",
    "            10: 'Pleural Other', 11: 'Pneumonia', 12: 'Pneumothorax', 13: 'Support Devices'\n",
    "        }\n",
    "\n",
    "        self.num_classes = 14\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        uid = self.keys[idx]\n",
    "\n",
    "        classes = torch.tensor(self.classes[uid]).float()\n",
    "\n",
    "        ## load text input ##\n",
    "        max_len_array = np.zeros(self.max_length, dtype='int')\n",
    "        cap_mask = np.zeros(self.max_length, dtype='int')\n",
    "        caption = np.array(self.datadict[uid]['token_ids'])\n",
    "        if len(caption) <= self.max_length:\n",
    "            cap_mask[:len(caption)] = 1\n",
    "            max_len_array[:len(caption)] = caption\n",
    "        else:\n",
    "            cap_mask[:] = 1\n",
    "            max_len_array = caption[:self.max_length]\n",
    "            max_len_array[-1] = self.__sep_id__\n",
    "        #         caption = max_len_array\n",
    "        cap_mask = cap_mask.astype(bool)\n",
    "        cap_lens = cap_mask.sum(-1)\n",
    "\n",
    "        return max_len_array, cap_mask, classes, uid, cap_lens\n",
    "\n",
    "\n",
    "def build_dataset(mode='train', cfg=None, out_dir=None):\n",
    "    data_dir = cfg.dataset_root\n",
    "    img_dir = os.path.join(data_dir, 'physionet.org/files/', 'mimic-cxr-jpg/2.0.0/')\n",
    "    with open(os.path.join(data_dir, 'lm_reports/class_label_mit.pkl'), 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    with open(os.path.join(data_dir, 'lm_reports/mimic_dataset_mit_normalized.pkl'), 'rb') as f2:\n",
    "        dataset_token = pickle.load(f2)\n",
    "    dataset['word2idx'] = dataset_token['word2idx']  # copy the token dicts to the dataset\n",
    "    dataset['idx2word'] = dataset_token['idx2word']\n",
    "\n",
    "    if mode == 'train':\n",
    "        data = MimicDataset(img_dir, dataset,\n",
    "                            max_length=cfg.max_length, mode=mode,\n",
    "                            transform=train_transform, log_dir=out_dir)\n",
    "        return data\n",
    "\n",
    "    elif mode == 'val':\n",
    "        data = MimicDataset(img_dir, dataset,\n",
    "                            max_length=cfg.max_length, mode=mode,\n",
    "                            transform=val_transform, log_dir=out_dir)\n",
    "        return data\n",
    "\n",
    "    elif mode == 'val2':\n",
    "        data = MimicDataset(img_dir, dataset,\n",
    "                            max_length=cfg.max_length, mode=mode,\n",
    "                            transform=val_transform, log_dir=out_dir)\n",
    "        return data\n",
    "\n",
    "    elif mode == 'test':\n",
    "        data = MimicDataset(img_dir, dataset,\n",
    "                            max_length=cfg.max_length, mode=mode,\n",
    "                            transform=val_transform, log_dir=out_dir)\n",
    "        return data\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(f\"{mode} not supported\")\n",
    "\n",
    "\n",
    "## collate_fn for handling None type item due to image corruption ##\n",
    "## This will return batch size - broken image number ##\n",
    "def collate_fn_ignore_none(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    return torch.utils.data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set 3000 is loaded.\n",
      "Vocab size is 8411.\n",
      "Max length is 160\n"
     ]
    }
   ],
   "source": [
    "# cfg.max_length = 127\n",
    "\n",
    "test_set = build_dataset('val2', cfg)\n",
    "# test_set = build_dataset('test', cfg)\n",
    "print('Testing set %d is loaded.' % len(test_set))\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                test_set, batch_size=50, \n",
    "                collate_fn=collate_fn_ignore_none, drop_last=False,\n",
    "                shuffle=False, num_workers=8, pin_memory=False)\n",
    "print('Vocab size is %d.' % test_set.vocab_size)\n",
    "print('Max length is %d' % test_set.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert encoder with MaskedLMhead.\n",
      "Initiate text encoder from MLM pretrained parameters from: /media/My1TBSSD1/IPMI2021/output/MIMIC_mlm_2021_02_24_19_58_21/Model/text_encoder.pth\n",
      "Load image encoder checkpoint from: /media/My1TBSSD1/IPMI2021/output/MIMIC_class_mlm_cls_ft_2021_03_19_14_33_50/Model/Txt_class_model4.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bert_config = BertConfig(vocab_size=test_loader.dataset.vocab_size, hidden_size=512, num_hidden_layers=3,\n",
    "                    num_attention_heads=8, intermediate_size=2048, hidden_act='gelu',\n",
    "                    hidden_dropout_prob=cfg.hidden_dropout_prob, attention_probs_dropout_prob=cfg.attention_probs_dropout_prob,\n",
    "                    max_position_embeddings=512, layer_norm_eps=1e-12,\n",
    "                    initializer_range=0.02, type_vocab_size=2, pad_token_id=0)\n",
    "\n",
    "##### change the checkpoint path here #####\n",
    "cfg.text_encoder_path = '../../output/MIMIC_class_mlm_cls_ft_2021_03_19_14_33_50/Model/Txt_class_model4.pth'\n",
    "# ################### encoders ################################# #      \n",
    "image_encoder = Text_Classification(num_class=14, pretrained=False, cfg=cfg, bert_config=bert_config)\n",
    "\n",
    "if cfg.CUDA:\n",
    "    image_encoder = image_encoder.cuda()\n",
    "    \n",
    "if cfg.text_encoder_path != '':\n",
    "#     img_encoder_path = cfg.text_encoder_path.replace('text_encoder', 'image_encoder')\n",
    "    print('Load image encoder checkpoint from:', cfg.text_encoder_path)\n",
    "    state_dict = torch.load(cfg.text_encoder_path, map_location='cpu')\n",
    "    image_encoder.load_state_dict(state_dict['model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(cnn_model, dataloader_val):\n",
    "    cnn_model.eval()\n",
    "    val_data_iter = iter(dataloader_val)\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    class_auc = []\n",
    "    #####################################\n",
    "    for step in tqdm(range(len(val_data_iter))):  \n",
    "        captions, cap_masks, classes, uids, cap_lens = val_data_iter.next()\n",
    "        if cfg.CUDA:\n",
    "            captions, cap_masks, classes = captions.cuda(), cap_masks.cuda(), classes.cuda()\n",
    "\n",
    "        y_pred = cnn_model(captions, cap_masks)\n",
    "        y_pred_sigmoid = torch.sigmoid(y_pred)\n",
    "        y_preds.append(y_pred_sigmoid.detach().cpu().numpy())\n",
    "        y_trues.append(classes.detach().cpu().numpy())\n",
    "\n",
    "    y_preds = np.concatenate(y_preds,axis=0)\n",
    "    y_trues = np.concatenate(y_trues,axis=0)\n",
    "    for i in range(y_preds.shape[-1]):\n",
    "        class_auc.append(roc_auc_score(y_trues[:,i],y_preds[:,i]))\n",
    "\n",
    "    return class_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:01<00:00, 31.84it/s]\n"
     ]
    }
   ],
   "source": [
    "auc = evaluate(image_encoder, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atelectasis: 0.9919\n",
      "Cardiomegaly: 0.9901\n",
      "Consolidation: 0.9979\n",
      "Edema: 0.9944\n",
      "Enlarged Cardiomediastinum: 0.9882\n",
      "Fracture: 0.9892\n",
      "Lung Lesion: 0.9951\n",
      "Lung Opacity: 0.9860\n",
      "No Finding: 0.9866\n",
      "Pleural Effusion: 0.9943\n",
      "Pleural Other: 0.9972\n",
      "Pneumonia: 0.9834\n",
      "Pneumothorax: 0.9909\n",
      "Support Devices: 0.9845\n",
      "Avg: 0.9910\n",
      "wAvg: 0.9896\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(auc)):\n",
    "    print('%s: %.4f' % (test_loader.dataset.idx_to_class[idx], auc[idx]))\n",
    "\n",
    "avg= np.mean(np.array(auc)[[0,1,2,3,4,5,6,7,9,10,11,12,13]])\n",
    "print('Avg: %.4f' % avg)\n",
    "\n",
    "# weight = np.array([679, 808, 191, 659, 132, 78, 108, 974, 539, 990, 52, 309, 94, 1061]) # weight for hold_out_set\n",
    "# weight = np.array([958, 997, 233, 600, 174, 79, 168, 1134, 1636, 1243, 31, 361, 234, 1566]) # weight for val+test set\n",
    "# weight = np.array([566, 575, 131, 354, 110, 33, 105, 650, 1017, 710, 28, 227, 124, 881]) # weight for val2 set\n",
    "weight = np.array([566, 575, 131, 354, 110, 33, 105, 650, 710, 28, 227, 124, 881]) # weight for val2 set\n",
    "\n",
    "weight = weight / weight.sum()\n",
    "wavg = np.array(auc)[[0,1,2,3,4,5,6,7,9,10,11,12,13]] @ weight\n",
    "print('wAvg: %.4f' % wavg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atelectasis: 0.9343\n",
      "Cardiomegaly: 0.9346\n",
      "Consolidation: 0.9363\n",
      "Edema: 0.9568\n",
      "Enlarged Cardiomediastinum: 0.9324\n",
      "Fracture: 0.9727\n",
      "Lung Lesion: 0.9556\n",
      "Lung Opacity: 0.9425\n",
      "No Finding: 0.9703\n",
      "Pleural Effusion: 0.9668\n",
      "Pleural Other: 0.9353\n",
      "Pneumonia: 0.9148\n",
      "Pneumothorax: 0.9694\n",
      "Support Devices: 0.9695\n",
      "Avg: 0.9478\n",
      "wAvg: 0.9501\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(auc)):\n",
    "    print('%s: %.4f' % (test_loader.dataset.idx_to_class[idx], auc[idx]))\n",
    "\n",
    "avg= np.mean(np.array(auc)[[0,1,2,3,4,5,6,7,9,10,11,12,13]])\n",
    "print('Avg: %.4f' % avg)\n",
    "\n",
    "# weight = np.array([679, 808, 191, 659, 132, 78, 108, 974, 539, 990, 52, 309, 94, 1061]) # weight for hold_out_set\n",
    "# weight = np.array([958, 997, 233, 600, 174, 79, 168, 1134, 1636, 1243, 31, 361, 234, 1566]) # weight for val+test set\n",
    "# weight = np.array([566, 575, 131, 354, 110, 33, 105, 650, 1017, 710, 28, 227, 124, 881]) # weight for val2 set\n",
    "weight = np.array([566, 575, 131, 354, 110, 33, 105, 650, 710, 28, 227, 124, 881]) # weight for val2 set\n",
    "\n",
    "weight = weight / weight.sum()\n",
    "wavg = np.array(auc)[[0,1,2,3,4,5,6,7,9,10,11,12,13]] @ weight\n",
    "print('wAvg: %.4f' % wavg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[958, 997, 233, 600, 174, 79, 168, 1134, 1636, 1243, 31, 361, 234, 1566]\n"
     ]
    }
   ],
   "source": [
    "## statistic for val sets and test sets\n",
    "hold = np.array([679, 808, 191, 659, 132, 78, 108, 974, 539, 990, 52, 309, 94, 1061])\n",
    "val1 = np.array([392, 422, 102, 246, 64, 46, 63, 484, 619, 533, 19, 134, 110, 685])\n",
    "val2 = np.array([566, 575, 131, 354, 110, 33, 105, 650, 1017, 710, 12, 227, 124, 881])\n",
    "print(list((val1+val2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566\n",
      "575\n",
      "131\n",
      "354\n",
      "110\n",
      "33\n",
      "105\n",
      "650\n",
      "1017\n",
      "710\n",
      "12\n",
      "227\n",
      "124\n",
      "881\n"
     ]
    }
   ],
   "source": [
    "for i in val2:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}